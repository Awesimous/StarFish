{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2afef313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T19:32:13.434271Z",
     "start_time": "2021-06-03T19:32:11.994451Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import geograpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6675b44d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T14:12:36.575218Z",
     "start_time": "2021-06-03T14:12:36.563484Z"
    }
   },
   "outputs": [],
   "source": [
    "# import first dataframe (you can save the games df by running: df.to_csv(r'path/filename', index=False))\n",
    "df = pd.read_csv('streamer_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd330646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:29:36.286963Z",
     "start_time": "2021-06-02T18:29:36.267385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>AVG Viewers</th>\n",
       "      <th>Time Streamed</th>\n",
       "      <th>All Time Peak Viewers</th>\n",
       "      <th>Hours Watched</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Followers Gained</th>\n",
       "      <th>Total Followers</th>\n",
       "      <th>Total Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tommyinnit</td>\n",
       "      <td>195782</td>\n",
       "      <td>14.3hours</td>\n",
       "      <td>650237</td>\n",
       "      <td>2806209</td>\n",
       "      <td>2</td>\n",
       "      <td>+334307</td>\n",
       "      <td>5499713</td>\n",
       "      <td>49185807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quackity</td>\n",
       "      <td>158364</td>\n",
       "      <td>10.2hours</td>\n",
       "      <td>381550</td>\n",
       "      <td>1620588</td>\n",
       "      <td>4</td>\n",
       "      <td>+198959</td>\n",
       "      <td>3471874</td>\n",
       "      <td>23178122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sapnap</td>\n",
       "      <td>129001</td>\n",
       "      <td>9.2hours</td>\n",
       "      <td>287152</td>\n",
       "      <td>1188960</td>\n",
       "      <td>8</td>\n",
       "      <td>+183191</td>\n",
       "      <td>2237876</td>\n",
       "      <td>8740493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auronplay</td>\n",
       "      <td>113520</td>\n",
       "      <td>109.4hours</td>\n",
       "      <td>313347</td>\n",
       "      <td>12419097</td>\n",
       "      <td>3</td>\n",
       "      <td>+341562</td>\n",
       "      <td>8741858</td>\n",
       "      <td>142994817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xQcOW</td>\n",
       "      <td>109059</td>\n",
       "      <td>339.9hours</td>\n",
       "      <td>222720</td>\n",
       "      <td>37072768</td>\n",
       "      <td>1</td>\n",
       "      <td>+182238</td>\n",
       "      <td>5776761</td>\n",
       "      <td>361856811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AdinRoss</td>\n",
       "      <td>107816</td>\n",
       "      <td>83.4hours</td>\n",
       "      <td>254923</td>\n",
       "      <td>8986453</td>\n",
       "      <td>7</td>\n",
       "      <td>+837941</td>\n",
       "      <td>3946089</td>\n",
       "      <td>21778759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WilburSoot</td>\n",
       "      <td>105874</td>\n",
       "      <td>8.3hours</td>\n",
       "      <td>215211</td>\n",
       "      <td>878604</td>\n",
       "      <td>15</td>\n",
       "      <td>+219086</td>\n",
       "      <td>3356385</td>\n",
       "      <td>15913013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ibai</td>\n",
       "      <td>98068</td>\n",
       "      <td>111.1hours</td>\n",
       "      <td>1538645</td>\n",
       "      <td>10898658</td>\n",
       "      <td>5</td>\n",
       "      <td>+321873</td>\n",
       "      <td>6204120</td>\n",
       "      <td>204197597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tubbo</td>\n",
       "      <td>92966</td>\n",
       "      <td>15.2hours</td>\n",
       "      <td>332671</td>\n",
       "      <td>1408437</td>\n",
       "      <td>17</td>\n",
       "      <td>+179383</td>\n",
       "      <td>3649547</td>\n",
       "      <td>45962620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCK_Korea</td>\n",
       "      <td>90113</td>\n",
       "      <td>89.3hours</td>\n",
       "      <td>365983</td>\n",
       "      <td>8044086</td>\n",
       "      <td>9</td>\n",
       "      <td>+46689</td>\n",
       "      <td>922251</td>\n",
       "      <td>268647537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RanbooLive</td>\n",
       "      <td>87705</td>\n",
       "      <td>106.6hours</td>\n",
       "      <td>346132</td>\n",
       "      <td>9350811</td>\n",
       "      <td>10</td>\n",
       "      <td>+297717</td>\n",
       "      <td>2889972</td>\n",
       "      <td>41353249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RocketLeague</td>\n",
       "      <td>80301</td>\n",
       "      <td>69.2hours</td>\n",
       "      <td>214930</td>\n",
       "      <td>5556826</td>\n",
       "      <td>13</td>\n",
       "      <td>+103074</td>\n",
       "      <td>3162189</td>\n",
       "      <td>245021264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>#13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Riot Games</td>\n",
       "      <td>78315</td>\n",
       "      <td>192.2hours</td>\n",
       "      <td>654205</td>\n",
       "      <td>15052113</td>\n",
       "      <td>6</td>\n",
       "      <td>+180549</td>\n",
       "      <td>5145477</td>\n",
       "      <td>1283791496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ThisIsNotGeorgeNotFound</td>\n",
       "      <td>75837</td>\n",
       "      <td>19.4hours</td>\n",
       "      <td>114463</td>\n",
       "      <td>1473757</td>\n",
       "      <td>23</td>\n",
       "      <td>+237958</td>\n",
       "      <td>793752</td>\n",
       "      <td>2026883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>#15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rainbow6</td>\n",
       "      <td>71417</td>\n",
       "      <td>116.3hours</td>\n",
       "      <td>191703</td>\n",
       "      <td>8303362</td>\n",
       "      <td>14</td>\n",
       "      <td>+105674</td>\n",
       "      <td>1993976</td>\n",
       "      <td>83988789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>#16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>loud_coringa</td>\n",
       "      <td>66990</td>\n",
       "      <td>120.9hours</td>\n",
       "      <td>144537</td>\n",
       "      <td>8101286</td>\n",
       "      <td>16</td>\n",
       "      <td>+153027</td>\n",
       "      <td>1890683</td>\n",
       "      <td>20149102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>#17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flashpoint</td>\n",
       "      <td>66883</td>\n",
       "      <td>125.1hours</td>\n",
       "      <td>128800</td>\n",
       "      <td>8363729</td>\n",
       "      <td>11</td>\n",
       "      <td>+160653</td>\n",
       "      <td>404895</td>\n",
       "      <td>118675590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>#18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TheRealKnossi</td>\n",
       "      <td>64403</td>\n",
       "      <td>95.5hours</td>\n",
       "      <td>336065</td>\n",
       "      <td>6151556</td>\n",
       "      <td>19</td>\n",
       "      <td>+95886</td>\n",
       "      <td>1674909</td>\n",
       "      <td>52372343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>#19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rubius</td>\n",
       "      <td>60892</td>\n",
       "      <td>116.1hours</td>\n",
       "      <td>344676</td>\n",
       "      <td>7068535</td>\n",
       "      <td>18</td>\n",
       "      <td>+252579</td>\n",
       "      <td>9188382</td>\n",
       "      <td>177882692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>#20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shroud</td>\n",
       "      <td>60253</td>\n",
       "      <td>205hours</td>\n",
       "      <td>516289</td>\n",
       "      <td>12349819</td>\n",
       "      <td>12</td>\n",
       "      <td>+187393</td>\n",
       "      <td>9259582</td>\n",
       "      <td>483658279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Unnamed: 1               Unnamed: 2 AVG Viewers Time Streamed  \\\n",
       "0          #1        NaN               tommyinnit      195782     14.3hours   \n",
       "1          #2        NaN                 Quackity      158364     10.2hours   \n",
       "2          #3        NaN                   Sapnap      129001      9.2hours   \n",
       "3          #4        NaN                auronplay      113520    109.4hours   \n",
       "4          #5        NaN                    xQcOW      109059    339.9hours   \n",
       "5          #6        NaN                 AdinRoss      107816     83.4hours   \n",
       "6          #7        NaN               WilburSoot      105874      8.3hours   \n",
       "7          #8        NaN                     ibai       98068    111.1hours   \n",
       "8          #9        NaN                    Tubbo       92966     15.2hours   \n",
       "9         #10        NaN                LCK_Korea       90113     89.3hours   \n",
       "10        #11        NaN               RanbooLive       87705    106.6hours   \n",
       "11        #12        NaN             RocketLeague       80301     69.2hours   \n",
       "12        #13        NaN               Riot Games       78315    192.2hours   \n",
       "14        #14        NaN  ThisIsNotGeorgeNotFound       75837     19.4hours   \n",
       "15        #15        NaN                 Rainbow6       71417    116.3hours   \n",
       "16        #16        NaN             loud_coringa       66990    120.9hours   \n",
       "17        #17        NaN               Flashpoint       66883    125.1hours   \n",
       "18        #18        NaN            TheRealKnossi       64403     95.5hours   \n",
       "19        #19        NaN                   Rubius       60892    116.1hours   \n",
       "20        #20        NaN                   shroud       60253      205hours   \n",
       "\n",
       "   All Time Peak Viewers Hours Watched Rank Followers Gained Total Followers  \\\n",
       "0                 650237       2806209    2          +334307         5499713   \n",
       "1                 381550       1620588    4          +198959         3471874   \n",
       "2                 287152       1188960    8          +183191         2237876   \n",
       "3                 313347      12419097    3          +341562         8741858   \n",
       "4                 222720      37072768    1          +182238         5776761   \n",
       "5                 254923       8986453    7          +837941         3946089   \n",
       "6                 215211        878604   15          +219086         3356385   \n",
       "7                1538645      10898658    5          +321873         6204120   \n",
       "8                 332671       1408437   17          +179383         3649547   \n",
       "9                 365983       8044086    9           +46689          922251   \n",
       "10                346132       9350811   10          +297717         2889972   \n",
       "11                214930       5556826   13          +103074         3162189   \n",
       "12                654205      15052113    6          +180549         5145477   \n",
       "14                114463       1473757   23          +237958          793752   \n",
       "15                191703       8303362   14          +105674         1993976   \n",
       "16                144537       8101286   16          +153027         1890683   \n",
       "17                128800       8363729   11          +160653          404895   \n",
       "18                336065       6151556   19           +95886         1674909   \n",
       "19                344676       7068535   18          +252579         9188382   \n",
       "20                516289      12349819   12          +187393         9259582   \n",
       "\n",
       "   Total Views  \n",
       "0     49185807  \n",
       "1     23178122  \n",
       "2      8740493  \n",
       "3    142994817  \n",
       "4    361856811  \n",
       "5     21778759  \n",
       "6     15913013  \n",
       "7    204197597  \n",
       "8     45962620  \n",
       "9    268647537  \n",
       "10    41353249  \n",
       "11   245021264  \n",
       "12  1283791496  \n",
       "14     2026883  \n",
       "15    83988789  \n",
       "16    20149102  \n",
       "17   118675590  \n",
       "18    52372343  \n",
       "19   177882692  \n",
       "20   483658279  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20abde1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T14:12:40.984881Z",
     "start_time": "2021-06-03T14:12:40.961086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2450, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting rows that contain ads out of the way\n",
    "df = df[df[\"Time Streamed\"].str.contains(\"ads\")==False]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ae48dd",
   "metadata": {},
   "source": [
    "# defining Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dcc3b9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T19:37:06.172654Z",
     "start_time": "2021-06-03T19:37:06.169727Z"
    }
   },
   "outputs": [],
   "source": [
    "consumer_key= 'bKibXskdPmTTHlgHu5mRDpLBo'\n",
    "consumer_secret='KvdpsHm2KbiIeWoJzZVOr0ZND3nyai4wfVcc2VGhyeGdUd56VG' \n",
    "access_token= '798115618243411968-fj6xschYkqbNc9VoxMcMiLbrdQI23mX'\n",
    "access_token_secret= 'OSSL3iLHcUi8zLVsLrwdlMcpijAuoNoovAtzMHZfmSffz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c92da98",
   "metadata": {},
   "source": [
    "# First Tries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1110d1",
   "metadata": {},
   "source": [
    "## First Tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f149f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T20:58:00.748361Z",
     "start_time": "2021-06-02T20:58:00.439840Z"
    }
   },
   "outputs": [],
   "source": [
    "user = api.get_user('noway4u_sir')\n",
    "\n",
    "print(user.screen_name)\n",
    "print(user.followers_count)\n",
    "for friend in user.friends():\n",
    "    print(friend.screen_name)\n",
    "    print(friend.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "893e1ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:18:09.639961Z",
     "start_time": "2021-06-02T18:18:09.634701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.cursor.ItemIterator at 0x11c9f2e80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the search term and the date_since date as variables\n",
    "search_words = \"#shroud\"\n",
    "date_since = \"2018-11-16\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=date_since).items(5)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "904cc3cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:23:12.718488Z",
     "start_time": "2021-06-02T18:23:12.136376Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang=\"en\",\n",
    "                       since=date_since).items(10)\n",
    "\n",
    "# Collect a list of tweets\n",
    "shroud = [tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39698595",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:23:13.885661Z",
     "start_time": "2021-06-02T18:23:13.881342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A must read. #Shroud https://t.co/9iM3QlVPEv',\n",
       " 'A huge happy bday to @shroud!!! You‚Äôve had (and continue to have!) such a tremendously positive impact on the gamin‚Ä¶ https://t.co/UXhu2hngJz',\n",
       " 'Visage\\n.\\nWanted to draw something in ink, and always wanted to do Art Noveau justice. I think i did well this time‚Ä¶ https://t.co/ZY4cRylF8N',\n",
       " 'Happy Birthday to Shroud @shroud\\nhttps://t.co/ZGbPHfXwsp\\n#topstarbirthdays #Gemini #birthday #TwitchStar #Shroud‚Ä¶ https://t.co/Una1RQB79X',\n",
       " 'Happy Birthday Best Fps Player of All Time!\\n\\n#Shroud  ‚ù§üòéüêê https://t.co/QUobcEf1Le',\n",
       " 'Happy Birthday @shroud \\nSab Logitech ka products ghar courier kardena üòò\\n#shroud #c9 https://t.co/K9Ls0lY3cZ',\n",
       " '@shroud So badass, wish that whole guild joined my discord server. \\n#ShamelessSelfpromoTuesday \\n#logitech\\n#Shroud\\n#Yoofa\\n#checkout',\n",
       " '#shroud is now streaming #World of Warcraft https://t.co/Z9AuWBNt5p',\n",
       " 'Happy birthday ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏èüéâ@shroud \\nHave a good one \\n\\n#shroud https://t.co/5DvdIOJXWq',\n",
       " 'RT @NevFailsTV: #Ludwig, #AdinRoss, QTCinderella DRAMA | #Summit1G on #Shroud #xQc Take | #QTCinderella Blasts AdinRoss | StreamerTvüì∫ #Twit‚Ä¶']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shroud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02db7c7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T19:37:25.772771Z",
     "start_time": "2021-06-03T19:37:25.761005Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4c091fb5fe99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tweets = tw.Cursor(api.search, \n\u001b[0m\u001b[1;32m      2\u001b[0m                            \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                            \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            since=date_since).items(15)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api' is not defined"
     ]
    }
   ],
   "source": [
    "tweets = tw.Cursor(api.search, \n",
    "                           q=search_words,\n",
    "                           lang=\"en\",\n",
    "                           since=date_since).items(15)\n",
    "\n",
    "users_locs = [[tweet.user.screen_name, tweet.user.location] for tweet in tweets]\n",
    "users_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52aee58c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:24:37.819859Z",
     "start_time": "2021-06-02T18:24:37.806317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>therealjoshmc</td>\n",
       "      <td>Florida, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrizzledGamer</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jetromagcale</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>topstarbdays</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virlix1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jakati68</td>\n",
       "      <td>Bengaluru South, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yoofatv</td>\n",
       "      <td>Missoula, MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Project410</td>\n",
       "      <td>Four Ways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nackb0Y</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NinjaTt91</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RazerTT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NevFailsTV</td>\n",
       "      <td>Twitter UK-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TopLiveonTwitc1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AurorPhantom</td>\n",
       "      <td>Englewood, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jawbreakarl</td>\n",
       "      <td>üáµüá≠</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user                location\n",
       "0     therealjoshmc            Florida, USA\n",
       "1     GrizzledGamer                        \n",
       "2      jetromagcale                        \n",
       "3      topstarbdays                     USA\n",
       "4           Virlix1                        \n",
       "5          jakati68  Bengaluru South, India\n",
       "6           yoofatv            Missoula, MT\n",
       "7        Project410               Four Ways\n",
       "8           Nackb0Y                        \n",
       "9         NinjaTt91                     USA\n",
       "10          RazerTT                        \n",
       "11       NevFailsTV           Twitter UK-US\n",
       "12  TopLiveonTwitc1                        \n",
       "13     AurorPhantom           Englewood, OH\n",
       "14      jawbreakarl                      üáµüá≠"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text = pd.DataFrame(data=users_locs, \n",
    "                    columns=['user', \"location\"])\n",
    "tweet_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdf9e55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:52:39.954070Z",
     "start_time": "2021-06-02T18:52:39.951411Z"
    }
   },
   "source": [
    "## Second Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca5bf144",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:48:43.710126Z",
     "start_time": "2021-06-02T18:48:41.544080Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KRMR47</td>\n",
       "      <td>Rheinberg, Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitch_Amk251</td>\n",
       "      <td>Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MoSiTingKeWeiDe</td>\n",
       "      <td>Berlin, Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SchnitzelSebl</td>\n",
       "      <td>Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Der_Schaumi</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Silenceuuu1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ZaveeLoL</td>\n",
       "      <td>Potsdam, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MxMinority</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DSchwatzer</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AlanTheTeemo</td>\n",
       "      <td>Berlin, Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ZaveeLoL</td>\n",
       "      <td>Potsdam, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pruhsi</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CookieLoLxx</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vildgaard1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vuffer2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xCruel_lol</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mazeADC</td>\n",
       "      <td>Bayern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DIEMdodoCoach</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DIEMdodoCoach</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Forpionlol</td>\n",
       "      <td>Torres Vedras, Portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GranitPubg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ashyva_LoL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EsportsNord</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>granitKMF</td>\n",
       "      <td>Stockholm, Sverige</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>granitgaming</td>\n",
       "      <td>Stockholm, Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MuterLoL</td>\n",
       "      <td>Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nyck</td>\n",
       "      <td>hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>IntCorax</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DSchwatzer</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EhmJaKlar</td>\n",
       "      <td>D√ºsseldorf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rammuslover69</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CHGClone</td>\n",
       "      <td>Olten, Schweiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>real_sioser</td>\n",
       "      <td>Schweiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LeMelar</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Pruhsi</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Santinus4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Saviour_lol</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pukistyle_</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>vantastisch86</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>OrgelOscar</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>YannickB96_</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AlanTheTeemo</td>\n",
       "      <td>Berlin, Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BigBossBaem</td>\n",
       "      <td>Hamburg, Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>WizardofTruth_</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user                 location\n",
       "0            KRMR47   Rheinberg, Deutschland\n",
       "1     Twitch_Amk251              Deutschland\n",
       "2   MoSiTingKeWeiDe      Berlin, Deutschland\n",
       "3     SchnitzelSebl              Deutschland\n",
       "4       Der_Schaumi                         \n",
       "5       Silenceuuu1                         \n",
       "6          ZaveeLoL         Potsdam, Germany\n",
       "7        MxMinority                         \n",
       "8        DSchwatzer                         \n",
       "9      AlanTheTeemo      Berlin, Deutschland\n",
       "10         ZaveeLoL         Potsdam, Germany\n",
       "11           Pruhsi                  Germany\n",
       "12      CookieLoLxx                   Sweden\n",
       "13       Vildgaard1                         \n",
       "14          Vuffer2                         \n",
       "15       xCruel_lol                         \n",
       "16          mazeADC                   Bayern\n",
       "17    DIEMdodoCoach                         \n",
       "18    DIEMdodoCoach                         \n",
       "19       Forpionlol  Torres Vedras, Portugal\n",
       "20       GranitPubg                         \n",
       "21       Ashyva_LoL                         \n",
       "22      EsportsNord                         \n",
       "23        granitKMF       Stockholm, Sverige\n",
       "24     granitgaming        Stockholm, Sweden\n",
       "25         MuterLoL                  Denmark\n",
       "26             nyck                  hamburg\n",
       "27         IntCorax                         \n",
       "28       DSchwatzer                         \n",
       "29        EhmJaKlar               D√ºsseldorf\n",
       "30    rammuslover69              Switzerland\n",
       "31         CHGClone           Olten, Schweiz\n",
       "32      real_sioser                  Schweiz\n",
       "33          LeMelar                         \n",
       "34           Pruhsi                  Germany\n",
       "35        Santinus4                         \n",
       "36      Saviour_lol                         \n",
       "37       pukistyle_                         \n",
       "38    vantastisch86                         \n",
       "39       OrgelOscar                         \n",
       "40      YannickB96_                         \n",
       "41     AlanTheTeemo      Berlin, Deutschland\n",
       "42      BigBossBaem     Hamburg, Deutschland\n",
       "43   WizardofTruth_                         "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second try\n",
    "# Define the search term and the date_since date as variables\n",
    "new_search = \"@Noway4u_sir\"\n",
    "date_since = \"2018-11-16\"\n",
    "\n",
    "tweets_noway = tw.Cursor(api.search, \n",
    "                           q=new_search,\n",
    "                           lang=\"en\",\n",
    "                           since=date_since).items(100)\n",
    "\n",
    "users_locs_2 = [[tweet.user.screen_name, tweet.user.location] for tweet in tweets_noway]\n",
    "users_locs_2\n",
    "\n",
    "tweet_text = pd.DataFrame(data=users_locs_2, \n",
    "                    columns=['user', \"location\"])\n",
    "tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e8d16e",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34c03193",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:48:57.723461Z",
     "start_time": "2021-06-02T18:48:57.719416Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    text = \"\".join(word for word in text if not word.isdigit()).lower()\n",
    "    word_tokens = word_tokenize(text)\n",
    "    text = [w for w in word_tokens if not w in stop_words]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c26b5221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:49:01.142645Z",
     "start_time": "2021-06-02T18:49:01.135279Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_text[\"clean_location\"] = tweet_text.location.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb3328af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:53:17.403097Z",
     "start_time": "2021-06-02T18:53:17.397042Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stop_words = set(stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c233e8a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T18:53:17.828672Z",
     "start_time": "2021-06-02T18:53:17.819359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('potsdam germany', 2.0),\n",
       " ('rheinberg deutschland', 1.0),\n",
       " ('stockholm sverige', 1.0),\n",
       " ('stockholm sweden', 1.0),\n",
       " ('olten schweiz', 1.0),\n",
       " ('hamburg deutschland', 1.0),\n",
       " ('torres vedras', 0.7071067811865476),\n",
       " ('vedras portugal', 0.7071067811865476)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Tuned TFidfvectorizer\n",
    "vec = TfidfVectorizer(ngram_range = (2,2), min_df=0.01, max_df = 0.05).fit(tweet_text.clean_location)\n",
    "\n",
    "vectors = vec.transform(tweet_text.clean_location) # Transform text to vectors\n",
    "\n",
    "sum_tfidf = vectors.sum(axis=0) # Sum of tfidf weighting by word\n",
    "\n",
    "tfidf_list = [(word, sum_tfidf[0, idx]) for word, idx in     vec.vocabulary_.items()]  # Get the word and associated weight\n",
    "\n",
    "sorted_tfidf_list =sorted(tfidf_list, key = lambda x: x[1], reverse=True)  # Sort\n",
    "\n",
    "sorted_tfidf_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1010b8dd",
   "metadata": {},
   "source": [
    "# Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c67cdc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T14:53:12.362945Z",
     "start_time": "2021-06-03T14:53:12.352982Z"
    }
   },
   "outputs": [],
   "source": [
    "def twitter_user_info(consumer_key, consumer_secret, access_token,access_token_secret, user):\n",
    "    '''Takes secrets, username on twitter to get twitter username, location of user and follower count'''\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit=True)\n",
    "    user = api.get_user(user)\n",
    "    location = user.location\n",
    "    name = user.screen_name\n",
    "    follower = user.followers_count\n",
    "    return pd.DataFrame(data=[[name, location, follower]], columns=['user','location of user', \"follower\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def twitter_,,,(consumer_key, consumer_secret, access_token,access_token_secret, user):\n",
    "#     '''Takes secrets, username on twitter to get twitter username and follower count'''\n",
    "#     auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "#     auth.set_access_token(access_token, access_token_secret)\n",
    "#     api = tw.API(auth, wait_on_rate_limit=True)\n",
    "#     user = api.get_user(user)\n",
    "#     name = user.screen_name\n",
    "#     follower = user.followers_count\n",
    "#     return pd.DataFrame(data=[[name, follower]], columns=['user', \"follower\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20766ad9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T14:53:00.136404Z",
     "start_time": "2021-06-03T14:52:59.789742Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = twitter_user_info(consumer_key, consumer_secret, access_token,access_token_secret, 'shroud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "368874fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T14:53:01.830090Z",
     "start_time": "2021-06-03T14:53:01.819168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>location of user</th>\n",
       "      <th>follower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shroud</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>1885139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user location of user  follower\n",
       "0  shroud  California, USA   1885139"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8071f1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:00:05.622684Z",
     "start_time": "2021-06-03T20:00:05.616850Z"
    }
   },
   "outputs": [],
   "source": [
    "def twitter_viewer_locations(consumer_key, consumer_secret, access_token,access_token_secret, user, date, item_count):\n",
    "    '''Takes secrets, username on twitter and starting date (format yyyy-mm-dd)'''\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit=True)\n",
    "    new_search = f\"@{user}\"\n",
    "    date_since = f\"{date}\"\n",
    "\n",
    "    tweets = tw.Cursor(api.search, \n",
    "                               q=new_search,\n",
    "                               lang=\"de\",\n",
    "                               since=date_since).items(item_count)\n",
    "    users_locs = [[tweet.user.screen_name, tweet.user.location] for tweet in tweets]\n",
    "    tweet_text = pd.DataFrame(data=users_locs, \n",
    "                        columns=['user', \"location\"])\n",
    "    locations = ' '.join(tweet_text['location'].to_list())\n",
    "    places = geograpy.get_geoPlace_context(text = locations)\n",
    "    frequent_locations = {'cities': places.cities, 'countries': places.countries}\n",
    "    return frequent_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be01c817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:16:12.492294Z",
     "start_time": "2021-06-03T20:16:12.489200Z"
    }
   },
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "from tweepy import Cursor\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "23801aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:21:11.889565Z",
     "start_time": "2021-06-03T20:21:11.885375Z"
    }
   },
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "49537703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:44:41.556704Z",
     "start_time": "2021-06-03T20:44:41.550450Z"
    }
   },
   "outputs": [],
   "source": [
    "def plenty_info(consumer_key, consumer_secret, access_token,access_token_secret, user):\n",
    "    '''Takes secrets, username on twitter to get twitter username, location of user and follower count'''\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit=True)\n",
    "    item = api.get_user(target)\n",
    "    name = item.name\n",
    "    location = item.location\n",
    "    screen_name = item.screen_name\n",
    "    description = item.description\n",
    "    status_count = item.statuses_count\n",
    "    friends_count = item.friends_count\n",
    "    followers_count = item.followers_count\n",
    "    tweets = item.statuses_count\n",
    "    account_created_date = item.created_at\n",
    "    delta = datetime.utcnow() - account_created_date\n",
    "    account_age_days = delta.days\n",
    "    tweets_per_day = round((float(tweets)/float(account_age_days)),2)\n",
    "    return pd.DataFrame(data=[[name, screen_name, location,  description, status_count, friends_count, followers_count, account_age_days, tweets_per_day]], columns=['usename','screen_name', 'location', 'description', 'statuses_count', 'friends_count', 'followers_count', 'Account age (in days)', 'tweets per day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "50685fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:44:42.458013Z",
     "start_time": "2021-06-03T20:44:42.159297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usename</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>Account age (in days)</th>\n",
       "      <th>tweets per day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frederik Hinteregger</td>\n",
       "      <td>noway4u_sir</td>\n",
       "      <td>M√ºnchen, Bayern</td>\n",
       "      <td>Twitchstreamer und Flammkuchenconnoisseur</td>\n",
       "      <td>5145</td>\n",
       "      <td>207</td>\n",
       "      <td>64198</td>\n",
       "      <td>2067</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                usename  screen_name         location  \\\n",
       "0  Frederik Hinteregger  noway4u_sir  M√ºnchen, Bayern   \n",
       "\n",
       "                                 description  statuses_count  friends_count  \\\n",
       "0  Twitchstreamer und Flammkuchenconnoisseur            5145            207   \n",
       "\n",
       "   followers_count  Account age (in days)  tweets per day  \n",
       "0            64198                   2067            2.49  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plenty_info(consumer_key, consumer_secret, access_token,access_token_secret, \"NoWay4u_sir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "461802eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:29:30.939755Z",
     "start_time": "2021-06-03T20:28:58.004449Z"
    }
   },
   "outputs": [],
   "source": [
    "hashtags = []\n",
    "mentions = []\n",
    "tweet_count = 0\n",
    "end_date = datetime.utcnow() - timedelta(days=365)\n",
    "for status in Cursor(api.user_timeline, id=target).items():\n",
    "    tweet_count += 1\n",
    "    if hasattr(status, \"entities\"):\n",
    "        entities = status.entities\n",
    "        if \"hashtags\" in entities:\n",
    "            for ent in entities[\"hashtags\"]:\n",
    "                if ent is not None:\n",
    "                    if \"text\" in ent:\n",
    "                        hashtag = ent[\"text\"]\n",
    "                        if hashtag is not None:\n",
    "                            hashtags.append(hashtag)\n",
    "        if \"user_mentions\" in entities:\n",
    "            for ent in entities[\"user_mentions\"]:\n",
    "                if ent is not None:\n",
    "                    if \"screen_name\" in ent:\n",
    "                        name = ent[\"screen_name\"]\n",
    "                if name is not None:\n",
    "                    mentions.append(name)\n",
    "        if status.created_at < end_date:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5c5716e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:29:40.792842Z",
     "start_time": "2021-06-03T20:29:40.787288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most mentioned Twitter users:\n",
      "Broeki2\t35\n",
      "teamAHG\t21\n",
      "LoLSola\t15\n",
      "LPGjustJohnny\t15\n",
      "Xiohlol\t12\n",
      "itskarni\t11\n",
      "PandarEUW\t11\n",
      "paint_tainted\t10\n",
      "Agurinlol\t10\n",
      "Autophil_lol\t10\n",
      "Most used hashtags:\n",
      "ALDIGaming\t2\n",
      "Werbung\t2\n",
      "MagentaeTrophy\t2\n",
      "W√ºrfelqueue\t2\n",
      "PrimeLeague\t1\n",
      "aldigaming\t1\n",
      "AldiGaming\t1\n",
      "AllStar2020\t1\n",
      "Ad\t1\n",
      "chefsache\t1\n",
      "All done. Processed 1063 tweets.\n"
     ]
    }
   ],
   "source": [
    "print(\"Most mentioned Twitter users:\")\n",
    "for item, count in Counter(mentions).most_common(10):\n",
    "    print(item + \"\\t\" + str(count))\n",
    "\n",
    "print(\"Most used hashtags:\")\n",
    "for item, count in Counter(hashtags).most_common(10):\n",
    "    print(item + \"\\t\" + str(count))\n",
    "\n",
    "print(\"All done. Processed \" + str(tweet_count) + \" tweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db718e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T19:51:04.774844Z",
     "start_time": "2021-06-03T19:51:04.770358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" New Brunswick, Canada     Cologne, Germany Berlin, Germany     C√≥rdoba, Espa√±a  Ark Cradle Bosnia and Herzegovina  J  Italia Riverside, CA  Dortmund, Deutschland    Sainte-Verge, France he/himüè≥Ô∏è\\u200d‚ößÔ∏è  intj     London, England Graz, √ñsterreich   Beach mansion in Bristol   ùî±ùî¢ùîûùîØùî∞    Hinter dir (DE)  Enemy's Nexus Tokyo‚úàÔ∏èBerlin Enemy's Nexus  \""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf661693",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T19:52:04.254689Z",
     "start_time": "2021-06-03T19:52:04.112516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['London', 'Bristol', 'New Brunswick']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places = geograpy.get_geoPlace_context(text = locations)\n",
    "\n",
    "places.countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fabaf97",
   "metadata": {},
   "source": [
    "# Trying Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f66ff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:15:44.768483Z",
     "start_time": "2021-06-04T08:15:42.977425Z"
    }
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples\u001b[0m\n\n  Searched in:\n    - '/Users/home/nltk_data'\n    - '/Users/home/.pyenv/versions/3.8.6/envs/starfish/nltk_data'\n    - '/Users/home/.pyenv/versions/3.8.6/envs/starfish/share/nltk_data'\n    - '/Users/home/.pyenv/versions/3.8.6/envs/starfish/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/starfish/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/starfish/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples.zip/twitter_samples/\u001b[0m\n\n  Searched in:\n    - '/Users/home/nltk_data'\n    - '/Users/home/.pyenv/versions/3.8.6/envs/starfish/nltk_data'\n    - '/Users/home/.pyenv/versions/3.8.6/envs/starfish/share/nltk_data'\n    - '/Users/home/.pyenv/versions/3.8.6/envs/starfish/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-23f399fdccb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mpositive_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positive_tweets.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mnegative_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'negative_tweets.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tweets.20150430-223406.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/starfish/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/starfish/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/starfish/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/starfish/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples\u001b[0m\n\n  Searched in:\n    - '/Users/home/nltk_data'\n    - '/Users/home/.pyenv/versions/3.8.6/envs/starfish/nltk_data'\n    - '/Users/home/.pyenv/versions/3.8.6/envs/starfish/share/nltk_data'\n    - '/Users/home/.pyenv/versions/3.8.6/envs/starfish/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
    "\n",
    "import re, string, random\n",
    "\n",
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens\n",
    "\n",
    "def get_all_words(cleaned_tokens_list):\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        for token in tokens:\n",
    "            yield token\n",
    "\n",
    "def get_tweets_for_model(cleaned_tokens_list):\n",
    "    for tweet_tokens in cleaned_tokens_list:\n",
    "        yield dict([token, True] for token in tweet_tokens)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "    negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "    text = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "    tweet_tokens = twitter_samples.tokenized('positive_tweets.json')[0]\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    positive_tweet_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "    negative_tweet_tokens = twitter_samples.tokenized('negative_tweets.json')\n",
    "\n",
    "    positive_cleaned_tokens_list = []\n",
    "    negative_cleaned_tokens_list = []\n",
    "\n",
    "    for tokens in positive_tweet_tokens:\n",
    "        positive_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "    for tokens in negative_tweet_tokens:\n",
    "        negative_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "    all_pos_words = get_all_words(positive_cleaned_tokens_list)\n",
    "\n",
    "    freq_dist_pos = FreqDist(all_pos_words)\n",
    "    print(freq_dist_pos.most_common(10))\n",
    "\n",
    "    positive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens_list)\n",
    "    negative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens_list)\n",
    "\n",
    "    positive_dataset = [(tweet_dict, \"Positive\")\n",
    "                         for tweet_dict in positive_tokens_for_model]\n",
    "\n",
    "    negative_dataset = [(tweet_dict, \"Negative\")\n",
    "                         for tweet_dict in negative_tokens_for_model]\n",
    "\n",
    "    dataset = positive_dataset + negative_dataset\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    train_data = dataset[:7000]\n",
    "    test_data = dataset[7000:]\n",
    "\n",
    "    classifier = NaiveBayesClassifier.train(train_data)\n",
    "\n",
    "    print(\"Accuracy is:\", classify.accuracy(classifier, test_data))\n",
    "\n",
    "    print(classifier.show_most_informative_features(10))\n",
    "\n",
    "    custom_tweet = \"I ordered just once from TerribleCo, they screwed up, never used the app again.\"\n",
    "\n",
    "    custom_tokens = remove_noise(word_tokenize(custom_tweet))\n",
    "\n",
    "    print(custom_tweet, classifier.classify(dict([token, True] for token in custom_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a7b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
